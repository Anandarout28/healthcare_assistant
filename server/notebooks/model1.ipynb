{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19f46672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17728 images belonging to 8 classes.\n",
      "Found 3796 images belonging to 8 classes.\n",
      "Found 3807 images belonging to 8 classes.\n",
      "Number of classes: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "DATA_PATH = 'C:/Users/routp/Downloads/skinIMG_split'\n",
    "IMG_SIZE = (128,128)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,  \n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,   \n",
    "    horizontal_flip = True,\n",
    ")\n",
    "test_val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_gen = test_val_datagen.flow_from_directory(\n",
    "    os.path.join(DATA_PATH, 'train'),\n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    ")\n",
    "val_gen = test_val_datagen.flow_from_directory(\n",
    "    os.path.join(DATA_PATH, 'validation'), \n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    ")\n",
    "test_gen = test_val_datagen.flow_from_directory(    \n",
    "    os.path.join(DATA_PATH, 'test'),\n",
    "    target_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False\n",
    ")\n",
    "num_classes = train_gen.num_classes\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bfb0c4",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "bsae_model = VGG16(\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    ")\n",
    "for layer in bsae_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = bsae_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x= Dropout(0.5)(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs = bsae_model.input, outputs = output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5944737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1486s\u001b[0m 3s/step - accuracy: 0.5125 - loss: 1.4699 - val_accuracy: 0.5595 - val_loss: 1.2824\n",
      "Epoch 2/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1501s\u001b[0m 3s/step - accuracy: 0.5534 - loss: 1.3207 - val_accuracy: 0.5806 - val_loss: 1.2159\n",
      "Epoch 3/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1463s\u001b[0m 3s/step - accuracy: 0.5740 - loss: 1.2677 - val_accuracy: 0.5925 - val_loss: 1.1817\n",
      "Epoch 4/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1461s\u001b[0m 3s/step - accuracy: 0.5833 - loss: 1.2262 - val_accuracy: 0.5998 - val_loss: 1.1591\n",
      "Epoch 5/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1490s\u001b[0m 3s/step - accuracy: 0.5912 - loss: 1.2111 - val_accuracy: 0.6014 - val_loss: 1.1426\n",
      "Epoch 6/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1450s\u001b[0m 3s/step - accuracy: 0.5984 - loss: 1.1876 - val_accuracy: 0.6072 - val_loss: 1.1288\n",
      "Epoch 7/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1467s\u001b[0m 3s/step - accuracy: 0.6010 - loss: 1.1756 - val_accuracy: 0.6101 - val_loss: 1.1155\n",
      "Epoch 8/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1454s\u001b[0m 3s/step - accuracy: 0.6056 - loss: 1.1567 - val_accuracy: 0.6164 - val_loss: 1.1032\n",
      "Epoch 9/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1459s\u001b[0m 3s/step - accuracy: 0.6093 - loss: 1.1421 - val_accuracy: 0.6151 - val_loss: 1.0974\n",
      "Epoch 10/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1444s\u001b[0m 3s/step - accuracy: 0.6143 - loss: 1.1310 - val_accuracy: 0.6156 - val_loss: 1.0883\n",
      "Epoch 11/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1477s\u001b[0m 3s/step - accuracy: 0.6168 - loss: 1.1223 - val_accuracy: 0.6196 - val_loss: 1.0785\n",
      "Epoch 12/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1393s\u001b[0m 3s/step - accuracy: 0.6197 - loss: 1.1108 - val_accuracy: 0.6201 - val_loss: 1.0728\n",
      "Epoch 13/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1369s\u001b[0m 2s/step - accuracy: 0.6220 - loss: 1.1003 - val_accuracy: 0.6209 - val_loss: 1.0681\n",
      "Epoch 14/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1379s\u001b[0m 2s/step - accuracy: 0.6254 - loss: 1.0907 - val_accuracy: 0.6241 - val_loss: 1.0621\n",
      "Epoch 15/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1343s\u001b[0m 2s/step - accuracy: 0.6279 - loss: 1.0891 - val_accuracy: 0.6288 - val_loss: 1.0563\n",
      "Epoch 16/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1346s\u001b[0m 2s/step - accuracy: 0.6277 - loss: 1.0768 - val_accuracy: 0.6315 - val_loss: 1.0506\n",
      "Epoch 17/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1338s\u001b[0m 2s/step - accuracy: 0.6346 - loss: 1.0714 - val_accuracy: 0.6288 - val_loss: 1.0467\n",
      "Epoch 18/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1341s\u001b[0m 2s/step - accuracy: 0.6326 - loss: 1.0626 - val_accuracy: 0.6333 - val_loss: 1.0419\n",
      "Epoch 19/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1334s\u001b[0m 2s/step - accuracy: 0.6337 - loss: 1.0545 - val_accuracy: 0.6344 - val_loss: 1.0371\n",
      "Epoch 20/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1335s\u001b[0m 2s/step - accuracy: 0.6382 - loss: 1.0529 - val_accuracy: 0.6367 - val_loss: 1.0349\n",
      "Epoch 21/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1323s\u001b[0m 2s/step - accuracy: 0.6398 - loss: 1.0449 - val_accuracy: 0.6378 - val_loss: 1.0300\n",
      "Epoch 22/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1336s\u001b[0m 2s/step - accuracy: 0.6389 - loss: 1.0392 - val_accuracy: 0.6359 - val_loss: 1.0283\n",
      "Epoch 23/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1334s\u001b[0m 2s/step - accuracy: 0.6455 - loss: 1.0358 - val_accuracy: 0.6375 - val_loss: 1.0244\n",
      "Epoch 24/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1334s\u001b[0m 2s/step - accuracy: 0.6431 - loss: 1.0275 - val_accuracy: 0.6401 - val_loss: 1.0206\n",
      "Epoch 25/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1339s\u001b[0m 2s/step - accuracy: 0.6453 - loss: 1.0242 - val_accuracy: 0.6415 - val_loss: 1.0189\n",
      "Epoch 26/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1340s\u001b[0m 2s/step - accuracy: 0.6480 - loss: 1.0162 - val_accuracy: 0.6399 - val_loss: 1.0164\n",
      "Epoch 27/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1326s\u001b[0m 2s/step - accuracy: 0.6496 - loss: 1.0143 - val_accuracy: 0.6444 - val_loss: 1.0135\n",
      "Epoch 28/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1338s\u001b[0m 2s/step - accuracy: 0.6550 - loss: 1.0061 - val_accuracy: 0.6428 - val_loss: 1.0113\n",
      "Epoch 29/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1746s\u001b[0m 3s/step - accuracy: 0.6546 - loss: 1.0033 - val_accuracy: 0.6438 - val_loss: 1.0070\n",
      "Epoch 30/30\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1389s\u001b[0m 3s/step - accuracy: 0.6566 - loss: 0.9965 - val_accuracy: 0.6449 - val_loss: 1.0051\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a learning rate schedule\n",
    "# This will decrease the learning rate every few epochs\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-5, # A very small starting learning rate\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "\n",
    "# Recompile the model with the learning rate schedule\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Now, fit the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=30 # Set a higher number of epochs for fine-tuning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ceac6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must call `compile()` before using the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Evaluate the model on the test dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_loss, test_acc = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFinal Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinal Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\routp\\Desktop\\health_dignosis\\server\\venv\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py:1050\u001b[39m, in \u001b[36mTrainer._assert_compile_called\u001b[39m\u001b[34m(self, method_name)\u001b[39m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1049\u001b[39m     msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcalling `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1050\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: You must call `compile()` before using the model."
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "\n",
    "print(f\"\\nFinal Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Final Test Accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc3998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved successfully as 'binary_cancer_model.h5'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeeed3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
